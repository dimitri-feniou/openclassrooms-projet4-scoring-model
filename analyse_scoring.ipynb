{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Projet 4 Openclassrooms : Construisez un modèle de scoring](#toc1_)    \n",
    "  - [Présentation du projet](#toc1_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Projet 4 Openclassrooms : Construisez un modèle de scoring](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Description de l'image](https://user.oc-static.com/upload/2023/03/24/16796540347308_Data%20Scientist-P7-01-banner.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Présentation du projet](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vous êtes Data Scientist au sein d'une société financière, nommée \"Prêt à dépenser\",  qui propose des crédits à la consommation pour des personnes ayant peu ou pas d'historique de prêt.<br>\n",
    "Elle souhaite donc développer un **algorithme de classification** pour aider à décider si un prêt peut être accordé à un client."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation des librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Import library\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.figure_factory as ff\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import make_scorer, mean_squared_error\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import missingno as msno\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas options display\n",
    "pd.options.display.max_rows = 1000\n",
    "pd.options.display.max_columns = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seaborn theme\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "plt.rcParams.update(\n",
    "    {\n",
    "        'xtick.labelsize': 25,\n",
    "        'ytick.labelsize': 25,\n",
    "        'axes.labelsize': 25,\n",
    "        'legend.fontsize': 25,\n",
    "        'axes.titlesize': 45,\n",
    "        'axes.titleweight': 'bold',\n",
    "        'axes.titleweight': 'bold'\n",
    "    })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chargement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Description des données via [Kernel Kaggle](https://www.kaggle.com/code/willkoehrsen/start-here-a-gentle-introduction/notebook): <br>\n",
    "\n",
    "   - application_train/application_test: the main training and testing data with information about each loan application at Home Credit. Every loan has its own row and is identified by the feature SK_ID_CURR. The training application data comes with the TARGET indicating 0: the loan was repaid or 1: the loan was not repaid.\n",
    "   - bureau: data concerning client's previous credits from other financial institutions. Each previous credit has its own row in bureau, but one loan in the application data can have multiple previous credits.\n",
    "   - bureau_balance: monthly data about the previous credits in bureau. Each row is one month of a previous credit, and a single previous credit can have multiple rows, one for each month of the credit length.\n",
    "   - previous_application: previous applications for loans at Home Credit of clients who have loans in the application data. Each current loan in the application data can have multiple previous loans. Each previous application has one row and is identified by the feature SK_ID_PREV.\n",
    "   - POS_CASH_BALANCE: monthly data about previous point of sale or cash loans clients have had with Home Credit. Each row is one month of a previous point of sale or cash loan, and a single previous loan can have many rows.\n",
    "   - credit_card_balance: monthly data about previous credit cards clients have had with Home Credit. Each row is one month of a credit card balance, and a single credit card can have many rows.\n",
    "    installments_payment: payment history for previous loans at Home Credit. There is one row for every made payment and one row for every missed payment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schéma des données "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![schema_dataset](https://storage.googleapis.com/kaggle-media/competitions/home-credit/home_credit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lectures des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset folder\n",
    "dataset_path = 'dataset'\n",
    "\n",
    "# List all files in the folder\n",
    "files = os.listdir(dataset_path)\n",
    "\n",
    "# Filter for CSV files\n",
    "csv_files = [file for file in files if file.endswith('.csv')]\n",
    "\n",
    "print(\n",
    "    f\"Fichier CSV de notre jeu de donnée ({len(files)} fichiers):  \\n {files}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dataframes with CSV from dataset\n",
    "\n",
    "app_train = pd.read_csv(\"dataset/application_train.csv\")\n",
    "app_test = pd.read_csv(\"dataset/application_test.csv\")\n",
    "bureau = pd.read_csv(\"dataset/bureau.csv\")\n",
    "bureau_balance = pd.read_csv(\"dataset/bureau_balance.csv\")\n",
    "credit_card_balance = pd.read_csv(\"dataset/credit_card_balance.csv\")\n",
    "installments_payments = pd.read_csv(\"dataset/installments_payments.csv\")\n",
    "pos_cash_balance = pd.read_csv(\"dataset/POS_CASH_balance.csv\")\n",
    "previous_application = pd.read_csv(\"dataset/previous_application.csv\")\n",
    "sample_submission = pd.read_csv(\"dataset/sample_submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get description csv of each dataset\n",
    "pd.set_option(\"max_colwidth\", 400)\n",
    "description = pd.read_csv(\n",
    "    \"dataset/HomeCredit_columns_description.csv\", encoding=\"ISO-8859-1\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Résumer des informations du dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_datasets(folder_path):\n",
    "    summary = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename == 'HomeCredit_columns_description.csv':\n",
    "            continue  # Skip the excluded file\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Calculate summary statistics\n",
    "        num_rows = df.shape[0]\n",
    "        num_cols = df.shape[1]\n",
    "        percent_missing = df.isnull().mean().mean() * 100\n",
    "        percent_duplicates = df.duplicated().mean() * 100\n",
    "        dtype_counts = df.dtypes.value_counts()\n",
    "        summary.append({\n",
    "            'Filename': filename,\n",
    "            'Num_Rows': num_rows,\n",
    "            'Num_Cols': num_cols,\n",
    "            'Percent_Missing': percent_missing,\n",
    "            'Percent_Duplicates': percent_duplicates,\n",
    "            'Object_Type_Count': dtype_counts.get('object', 0),\n",
    "            'Float_Type_Count': dtype_counts.get('float64', 0),\n",
    "            'Int_Type_Count': dtype_counts.get('int64', 0),\n",
    "            'Bool_Type_Count': dtype_counts.get('bool', 0)\n",
    "        })\n",
    "\n",
    "    summary_df = pd.DataFrame(summary)\n",
    "    return summary_df\n",
    "\n",
    "\n",
    "# Use function\n",
    "folder_path = 'dataset'\n",
    "dataset_summary = summarize_datasets(folder_path)\n",
    "display(dataset_summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Exploration des données: application_train.csv | test.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La première partie de l'exploration de nos données va se concentrer sur le jeu de donnée application_train.csv & test.csv,pour appronfondir l'analyse des features de ces principaux fichiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get shape of dataframes\n",
    "print('Nombre de features et ligne dans le dataframe app_train:', app_train.shape)\n",
    "print('Nombre de features et ligne dans le dataframe app_test:', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque de que nos données app_train contient beaucoup plus de données que app_test,avec **307511 observations** et **122 features**. On remarque aussi que une colonne est manquante par rapport à app_train. Nous allons vérifier quelle colonne diffère entre ces deux dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if 'TARGET' is the only difference\n",
    "print(\"Vérification de la colonne manquantes entre les deux dataframes\")\n",
    "display(app_train.columns.difference(app_test.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La colonne manquantes dans app_test est la valeur TARGET. C'est cette valeur que l'on veut prédire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of the Target column\n",
    "app_train['TARGET'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax, fig = plt.subplots(figsize=(20, 8))\n",
    "ax = sns.countplot(y='TARGET', data=app_train, palette=[\"darkblue\", \"darkred\"])\n",
    "ax.set_title(\"TARGET distribution\")\n",
    "\n",
    "for p in ax.patches:\n",
    "    percentage = '{:.1f}%'.format(\n",
    "        100 * p.get_width()/len(app_train.TARGET))\n",
    "    x = p.get_x() + p.get_width()\n",
    "    y = p.get_y() + p.get_height()/2\n",
    "    ax.annotate(percentage, (x, y), fontsize=20, fontweight='bold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque grâce a ce graphique une distribution de la colonne 'TARGET' très déséquilibrer,on a beaucoup de prêts remboursés que de prêt non-remboursés.Ce problème d'imbalance des classes peut réduire la performance de notre algorithmes d'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to see the completion of dataframe per column\n",
    "def missing_value_dataframe(dataframe: pd.DataFrame):\n",
    "    \"\"\"Function for calculating missing values per column to dataframe. \n",
    "    Get the percentage of non-missing and total missing values per column\n",
    "\n",
    "    parameters :\n",
    "        dataframe : pandas dataframe to calculate missing values\n",
    "    return :\n",
    "    Specific dataframe with missing values per column   \n",
    "    \"\"\"\n",
    "    # Count missing values per column\n",
    "    missing_count = dataframe.isnull().sum()\n",
    "\n",
    "    # Count non-missing values per column\n",
    "    non_missing_count = dataframe.notnull().sum()\n",
    "\n",
    "    # Calculate the total number of values per column\n",
    "    total_count = len(dataframe)\n",
    "\n",
    "    # Calculate the percentage of non-missing values\n",
    "    percentage_non_missing = (non_missing_count / total_count) * 100\n",
    "\n",
    "    # Create a new DataFrame with the values\n",
    "    df_missing_values = pd.DataFrame({\n",
    "        'Taux de remplissage': percentage_non_missing,\n",
    "        'Nombre de valeurs manquantes': missing_count})\n",
    "    df_missing_values = df_missing_values.sort_values(\n",
    "        by='Taux de remplissage', ascending=False)\n",
    "\n",
    "    return df_missing_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplly function to dataframe\n",
    "df_missing_values_app_train = missing_value_dataframe(app_train)\n",
    "\n",
    "filtered_df = df_missing_values_app_train[df_missing_values_app_train['Taux de remplissage'] < 100]\n",
    "display(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the count of missing values per column\n",
    "missing_counts = app_train.isnull().sum().sort_values(ascending=False)\n",
    "\n",
    "# Select columns with the most null value\n",
    "top_10_missing = missing_counts.head(50).index\n",
    "\n",
    "# Fitered the dataframe to keep top 10 missing columns\n",
    "df_filtered_10_missing = app_train[top_10_missing]\n",
    "\n",
    "# Use missingno.matrix() on a DataFrame filtered to include only these columns\n",
    "msno.matrix(df_filtered_10_missing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Certaines modèles telle-que XGboost peuvent gérer les valeurs manquantes sans impution. Nous avons plusieurs choix supprimer les colonnes avec trop de valeurs manquantes, les remplacer avec une méthodes d'imputation. Pour l'instant nous pouvons pas déterminer si nous allons garder ou non ces colonnes étant peu avancer dans l'analyse.\n",
    "Nous pouvons remarquer qu'un certain pattern ce dessine dans les valeurs manquantes et les valeurs sont les mêmes bien souvent que dans d'autres colonnes. On remarque aussi que les colonnes avec le plus de Nan correspondent à des caractéristique sur l'habitat et non sur les crédits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types des colonnes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant le nombre de types de colonnes différentes que nous avons, les variables INT et FLOAT sont des variables numérique et 'object' contient des string et sont des variables catégorielles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of column\n",
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons maintenant les colonnes 'object' (variables catégorielles) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of unique classes in each object column\n",
    "app_train.select_dtypes('object').apply(pd.Series.nunique, axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des variables catégorielles ont un nombre relativement petit d'entrées uniques. Nous devrons trouver un moyen de traiter ces variables catégorielles…"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anomalies dans notre jeu de donnée "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['DAYS_BIRTH'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que notre colonne 'DAYS_BIRTH' contient des valeurs négative car ils sont enregistrés par rapport à la demande de prêt en cours. Il est nécessaire de modifier cette variable pour obtenir des chiffres plus compréhensibles pour l'analyse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(app_train['DAYS_BIRTH'] / -365).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test if function was apply\n",
    "(app_train['DAYS_BIRTH']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(app_train, x='DAYS_BIRTH', nbins=30,\n",
    "                   title=\"Représentation de l'Age des clients\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['DAYS_EMPLOYED'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(app_train, x='DAYS_EMPLOYED', nbins=30,\n",
    "                   title=\"Représentation des jours d'emploi\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Idem ces données ne sont pas \"normales\" au sens où le Max. représente 1000 années (365243/365j). Est-ce un individu isolé? Plusieurs individus de l'échantillon?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"%0.0f values with 365243 days employed for training data\" %\n",
    "      len(app_train[app_train['DAYS_EMPLOYED'] == 365243]))\n",
    "print(\"%0.0f Total values from days employed for training data\" %\n",
    "      app_train.shape[0])\n",
    "print(\"***********************\")\n",
    "print(\"%0.0f values with 365243 days employed for testing data\" %\n",
    "      len(app_test[app_test['DAYS_EMPLOYED'] == 365243]))\n",
    "print(\"%0.0f Total values from days employed for testing data\" %\n",
    "      app_test.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an outliers flag column\n",
    "app_train['DAYS_EMPLOYED_OUTLIERS'] = app_train[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test['DAYS_EMPLOYED_OUTLIERS'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "\n",
    "# Replace outliers values with nan\n",
    "app_train['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create columns with DAYS_EMPLOYEMENT anomalies in app_test\n",
    "app_test['DAYS_EMPLOYED_ANOM'] = app_test[\"DAYS_EMPLOYED\"] == 365243\n",
    "app_test['DAYS_EMPLOYED'].replace({365243: np.nan}, inplace=True)\n",
    "print('There are %d anomalies in the test data out of %d entries' %\n",
    "      (app_test[\"DAYS_EMPLOYED_ANOM\"].sum(), len(app_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(app_train, x='DAYS_EMPLOYED', nbins=30,\n",
    "                   title=\"Représentation des jours d'emploi après remplacement des outliers\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse des variables Principales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous allons les principales features qui peuvent être interessante à analyser. Nous allons analyser certaines features en univarié pour voir les liens avec notre colonne TARGET.Nous voir l'impact de certaines features sur le nom remboursement d'un prêt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Mise à jour de la fonction pour calculer correctement les pourcentages\n",
    "\n",
    "\n",
    "def calculate_percentages(total_count, subset_count):\n",
    "    percentage = (subset_count / total_count) * 100\n",
    "    return f\"{percentage:.2f}%\"\n",
    "\n",
    "\n",
    "# Création de subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Tout les contrats\", \"Taux de non-remboursement en fonction du type de contrats\"))\n",
    "\n",
    "# Calcul du nombre total et des pourcentages pour chaque type de contrat\n",
    "total_cash_loans = app_train[app_train['NAME_CONTRACT_TYPE']\n",
    "                             == 'Cash loans'].shape[0]\n",
    "total_revolving_loans = app_train[app_train['NAME_CONTRACT_TYPE']\n",
    "                                  == 'Revolving loans'].shape[0]\n",
    "\n",
    "# Pour le premier plot\n",
    "cash_loans_percent = calculate_percentages(\n",
    "    app_train.shape[0], total_cash_loans)\n",
    "revolving_loans_percent = calculate_percentages(\n",
    "    app_train.shape[0], total_revolving_loans)\n",
    "\n",
    "# Ajout des traces pour le premier plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=['Cash loans', 'Revolving loans'], x=[total_cash_loans, total_revolving_loans], orientation='h',\n",
    "           marker=dict(color=['blue', 'red']), text=[cash_loans_percent, revolving_loans_percent]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Calcul des nombres et pourcentages pour les contrats avec TARGET == 1\n",
    "cash_loans_target_1 = app_train[(app_train['NAME_CONTRACT_TYPE'] == 'Cash loans') & (\n",
    "    app_train['TARGET'] == 1)].shape[0]\n",
    "revolving_loans_target_1 = app_train[(\n",
    "    app_train['NAME_CONTRACT_TYPE'] == 'Revolving loans') & (app_train['TARGET'] == 1)].shape[0]\n",
    "\n",
    "cash_loans_percent_target_1 = calculate_percentages(\n",
    "    total_cash_loans, cash_loans_target_1)\n",
    "revolving_loans_percent_target_1 = calculate_percentages(\n",
    "    total_revolving_loans, revolving_loans_target_1)\n",
    "\n",
    "# Ajout des traces pour le deuxième plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=['Cash loans', 'Revolving loans'], x=[cash_loans_target_1, revolving_loans_target_1], orientation='h',\n",
    "           marker=dict(color=['blue', 'red']), text=[cash_loans_percent_target_1, revolving_loans_percent_target_1]),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Mise à jour de la mise en page et affichage du plot\n",
    "fig.update_layout(height=600, width=800,\n",
    "                  title_text=\"Représentation des types de contrats\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur le premier graphique on remarque que les prêt renouvelable ne forme qu'une petit des prêts accordés (10%).Par contre il représente un grand nombre des prêts qui sont non-remboursés en proportion du nombre de prêts renouvelable accordés.\n",
    "**1 prêt renouvelable sur 2 n'est pas remboursés.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correctly calculate percentages\n",
    "def calculate_percentages(total_count, subset_count):\n",
    "    percentage = (subset_count / total_count) * 100\n",
    "    return f\"{percentage:.2f}%\"\n",
    "\n",
    "\n",
    "# Creating subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Contrats attribués en fonction du genre\", \"Taux de non-remboursement en fonction du genre\"))\n",
    "\n",
    "# Calculating total counts and percentages for each gender category\n",
    "total_male = app_train[app_train['CODE_GENDER'] == 'M'].shape[0]\n",
    "total_female = app_train[app_train['CODE_GENDER'] == 'F'].shape[0]\n",
    "\n",
    "# For the first plot\n",
    "male_percent = calculate_percentages(app_train.shape[0], total_male)\n",
    "female_percent = calculate_percentages(app_train.shape[0], total_female)\n",
    "\n",
    "# Adding traces for the first plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=['Male', 'Female'], x=[total_male, total_female], orientation='h',\n",
    "           marker=dict(color=['green', 'purple']), text=[male_percent, female_percent]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Calculating counts and percentages for gender categories with TARGET == 1\n",
    "male_target_1 = app_train[(app_train['CODE_GENDER'] == 'M') & (\n",
    "    app_train['TARGET'] == 1)].shape[0]\n",
    "female_target_1 = app_train[(app_train['CODE_GENDER'] == 'F') & (\n",
    "    app_train['TARGET'] == 1)].shape[0]\n",
    "\n",
    "male_percent_target_1 = calculate_percentages(\n",
    "    app_train.shape[0], male_target_1)\n",
    "female_percent_target_1 = calculate_percentages(\n",
    "    app_train.shape[0], female_target_1)\n",
    "\n",
    "# Adding traces for the second plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=['Male', 'Female'], x=[male_target_1, female_target_1], orientation='h',\n",
    "           marker=dict(color=['green', 'purple']), text=[male_percent_target_1, female_percent_target_1]),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Updating the layout and displaying the plot\n",
    "fig.update_layout(height=600, width=1000,\n",
    "                  title_text=\"Représentation des prêts en fonction du Genre\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sur ce graphique on remarque les clients sont le double des clients masculin. En porportion les hommes ont plus de chances de ne pas remboursés leurs prêts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "\n",
    "# Function to correctly calculate percentages for subsets\n",
    "\n",
    "\n",
    "def calculate_percentages(total_count, subset_count):\n",
    "    percentage = (subset_count / total_count) * 100\n",
    "    return f\"{percentage:.2f}%\"\n",
    "\n",
    "\n",
    "# Creating subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés propriétaire Voiture\", \"Taux de non-remboursement propriétaire voiture\"))\n",
    "\n",
    "# Calculating total counts and percentages for car ownership categories\n",
    "total_own_car = app_train[app_train['FLAG_OWN_CAR'] == 'Y'].shape[0]\n",
    "total_no_car = app_train[app_train['FLAG_OWN_CAR'] == 'N'].shape[0]\n",
    "\n",
    "# For the first plot\n",
    "own_car_percent = calculate_percentages(app_train.shape[0], total_own_car)\n",
    "no_car_percent = calculate_percentages(app_train.shape[0], total_no_car)\n",
    "\n",
    "# Adding traces for the first plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=['Propriétaire de Voiture', 'Non propriétaire'], x=[total_own_car, total_no_car], orientation='h',\n",
    "           marker=dict(color=['green', 'gray']), text=[own_car_percent, no_car_percent]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Calculating counts and percentages for car ownership categories with TARGET == 1\n",
    "own_car_target_1 = app_train[(app_train['FLAG_OWN_CAR'] == 'Y') & (\n",
    "    app_train['TARGET'] == 1)].shape[0]\n",
    "no_car_target_1 = app_train[(app_train['FLAG_OWN_CAR'] == 'N') & (\n",
    "    app_train['TARGET'] == 1)].shape[0]\n",
    "\n",
    "own_car_percent_target_1 = calculate_percentages(\n",
    "    total_own_car, own_car_target_1)\n",
    "no_car_percent_target_1 = calculate_percentages(total_no_car, no_car_target_1)\n",
    "\n",
    "# Adding traces for the second plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=['Propriétaire de Voiture', 'Non propriétaire'], x=[own_car_target_1, no_car_target_1], orientation='h',\n",
    "           marker=dict(color=['green', 'gray']), text=[own_car_percent_target_1, no_car_percent_target_1]),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Updating the layout and displaying the plot\n",
    "fig.update_layout(height=600, width=1000,\n",
    "                  title_text=\"Répresentation des prêts en fonction des propriétaires de Voiture \", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les deux catégories (propriétaire ou non) ont des taux de non-remboursement d'environ 8%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to correctly calculate percentages for subsets\n",
    "def calculate_percentages(total_count, subset_count):\n",
    "    percentage = (subset_count / total_count) * 100\n",
    "    return f\"{percentage:.2f}%\"\n",
    "\n",
    "\n",
    "# Creating subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés par Statut familial\", \"Taux de non-remboursement par Statut familial\"))\n",
    "\n",
    "# Define a list of colors\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', '#8c564b']\n",
    "\n",
    "# List of family statuses\n",
    "family_statuses = ['Single / not married', 'Married',\n",
    "                   'Civil marriage', 'Widow', 'Separated', 'Unknown']\n",
    "\n",
    "# Calculating total counts for each family status\n",
    "status_counts = [(status, app_train[app_train['NAME_FAMILY_STATUS']\n",
    "                  == status].shape[0]) for status in family_statuses]\n",
    "\n",
    "# Sorting by counts\n",
    "status_counts_sorted = sorted(status_counts, key=lambda x: x[1])\n",
    "\n",
    "# Splitting the tuples for plotting\n",
    "statuses_sorted, counts_sorted = zip(*status_counts_sorted)\n",
    "\n",
    "# Calculating percentages\n",
    "percentages_sorted = [calculate_percentages(\n",
    "    app_train.shape[0], count) for count in counts_sorted]\n",
    "\n",
    "# Adding traces for the first plot, sorted by counts, with colors\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(statuses_sorted), x=list(counts_sorted), orientation='h',\n",
    "           marker=dict(color=colors), text=percentages_sorted),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Calculating counts and percentages for family status categories with TARGET == 1, and sorting\n",
    "counts_target_1_sorted = [app_train[(app_train['NAME_FAMILY_STATUS'] == status) & (\n",
    "    app_train['TARGET'] == 1)].shape[0] for status in statuses_sorted]\n",
    "percentages_target_1_sorted = [calculate_percentages(\n",
    "    counts_sorted[i], count_target_1) for i, count_target_1 in enumerate(counts_target_1_sorted)]\n",
    "\n",
    "# Adding traces for the second plot, sorted by counts with TARGET == 1, with colors\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(statuses_sorted), x=counts_target_1_sorted, orientation='h',\n",
    "           marker=dict(color=colors), text=percentages_target_1_sorted),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Updating the layout and displaying the plot\n",
    "fig.update_layout(height=600, width=1000,\n",
    "                  title_text=\"Répresentation des prêts en fonction du Statut familial\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des clients sont mariés, suivis des célibataires / non mariés et des mariages civils.\n",
    "\n",
    "En termes de pourcentage de non-remboursement du prêt, le mariage civil a le pourcentage le plus élevé de non-remboursement (10%), la veuve étant le plus bas (à l'exception de l'inconnu)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'app_train' is your DataFrame\n",
    "\n",
    "# Define a list of colors for the different income types\n",
    "colors = ['#17becf', '#bcbd22', '#7f7f7f', '#e377c2',\n",
    "          '#8c564b', '#9467bd', '#d62728', '#2ca02c']\n",
    "\n",
    "# List of income types\n",
    "income_types = ['Working', 'State servant', 'Commercial associate',\n",
    "                'Pensioner', 'Unemployed', 'Student', 'Businessman', 'Maternity leave']\n",
    "\n",
    "# Calculating total counts for each income type\n",
    "income_counts = [(income, app_train[app_train['NAME_INCOME_TYPE']\n",
    "                  == income].shape[0]) for income in income_types]\n",
    "\n",
    "# Sorting by counts\n",
    "income_counts_sorted = sorted(income_counts, key=lambda x: x[1])\n",
    "\n",
    "# Splitting the tuples for plotting\n",
    "incomes_sorted, counts_sorted = zip(*income_counts_sorted)\n",
    "\n",
    "# Calculating percentages\n",
    "percentages_sorted = [calculate_percentages(\n",
    "    app_train.shape[0], count) for count in counts_sorted]\n",
    "\n",
    "# Creating subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés par Type de revenu\", \"Taux de non-remboursement par Type de revenu\"))\n",
    "\n",
    "# Adding traces for the first plot, sorted by counts, with colors\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(incomes_sorted), x=list(counts_sorted), orientation='h',\n",
    "           marker=dict(color=colors), text=percentages_sorted),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Calculating counts and percentages for income types with TARGET == 1, and sorting\n",
    "counts_target_1_sorted = [app_train[(app_train['NAME_INCOME_TYPE'] == income) & (\n",
    "    app_train['TARGET'] == 1)].shape[0] for income in incomes_sorted]\n",
    "percentages_target_1_sorted = [calculate_percentages(\n",
    "    counts_sorted[i], count_target_1) for i, count_target_1 in enumerate(counts_target_1_sorted)]\n",
    "print(counts_target_1_sorted)\n",
    "# Adding traces for the second plot, sorted by counts with TARGET == 1, with colors\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(incomes_sorted), x=counts_target_1_sorted, orientation='h',\n",
    "           marker=dict(color=colors), text=percentages_target_1_sorted),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Updating the layout and displaying the plot\n",
    "fig.update_layout(height=600, width=1000,\n",
    "                  title_text=\"Répresentation des prêts en fonction du Type de revenu\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "La plupart des demandeurs de prêts sont des revenus du travail, suivis par un associé commercial, un retraité et un fonctionnaire.\n",
    "\n",
    "Les demandeurs avec le type de revenu Congé de maternité ont un ratio de près de 40% de prêts non remboursés, suivis des chômeurs (37%). Les autres types de revenus sont inférieurs à la moyenne de 10% pour ne pas rembourser les prêts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste des types d'occupation\n",
    "occupation_types = [\n",
    "    'Laborers', 'Core staff', 'Accountants', 'Managers',\n",
    "    'Drivers', 'Sales staff', 'Cleaning staff', 'Cooking staff',\n",
    "    'Private service staff', 'Medicine staff', 'Security staff',\n",
    "    'High skill tech staff', 'Waiters/barmen staff',\n",
    "    'Low-skill Laborers', 'Realty agents', 'Secretaries', 'IT staff',\n",
    "    'HR staff'\n",
    "]\n",
    "\n",
    "# Calcul des totaux pour chaque type d'occupation\n",
    "occupation_counts = [(occupation, app_train[app_train['OCCUPATION_TYPE']\n",
    "                      == occupation].shape[0]) for occupation in occupation_types]\n",
    "\n",
    "# Tri par les totaux\n",
    "occupation_counts_sorted_by_total = sorted(\n",
    "    occupation_counts, key=lambda x: x[1])\n",
    "\n",
    "# Séparation des tuples pour le traçage, triés par total\n",
    "occupations_sorted_by_total, counts_sorted_by_total = zip(\n",
    "    *occupation_counts_sorted_by_total)\n",
    "\n",
    "# Calcul des pourcentages\n",
    "percentages_sorted_by_total = [calculate_percentages(\n",
    "    app_train.shape[0], count) for count in counts_sorted_by_total]\n",
    "\n",
    "# Calcul des totaux et des pourcentages pour les cas avec TARGET == 1, et tri\n",
    "occupation_counts_with_target = [(occupation, app_train[(app_train['OCCUPATION_TYPE'] == occupation) & (\n",
    "    app_train['TARGET'] == 1)].shape[0]) for occupation in occupation_types]\n",
    "occupation_counts_sorted_by_target = sorted(\n",
    "    occupation_counts_with_target, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# Séparation des tuples pour le traçage, triés par TARGET == 1\n",
    "occupations_sorted_by_target, counts_sorted_by_target = zip(\n",
    "    *occupation_counts_sorted_by_target)\n",
    "percentages_sorted_by_target = [calculate_percentages(\n",
    "    count, app_train[app_train['OCCUPATION_TYPE'] == occupation].shape[0]) for occupation, count in occupation_counts_sorted_by_target]\n",
    "\n",
    "# Création de subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés par Type d'occupation\", \"Taux de non-remboursement par Type d'occupation\"))\n",
    "\n",
    "# Ajout des traces pour le premier plot, trié par les totaux\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(occupations_sorted_by_total), x=list(counts_sorted_by_total), orientation='h',\n",
    "           marker=dict(color=colors), text=percentages_sorted_by_total),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Ajout des traces pour le second plot, trié par TARGET == 1\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(occupations_sorted_by_target), x=list(counts_sorted_by_target), orientation='h',\n",
    "           marker=dict(color=colors), text=percentages_sorted_by_target),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Mise à jour de la disposition et affichage du graphique\n",
    "fig.update_layout(height=600, width=1000,\n",
    "                  title_text=\"Représentation des prêts en fonction du Type d'occupation\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La plupart des prêts sont contractés par des ouvriers, suivis par les vendeurs/commerciaux. Le personnel informatique prend le montant de prêts le plus bas.\n",
    "\n",
    "La catégorie avec le pourcentage le plus élevé de prêts non remboursés est celle des ouvriers peu qualifiés (plus de 17%), suivis des chauffeurs et des serveurs / barmen, du personnel de sécurité, des ouvriers et du personnel de cuisine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of colors for the different education types\n",
    "colors = ['#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd']\n",
    "\n",
    "# List of education types\n",
    "education_types = [\n",
    "    'Secondary / secondary special',\n",
    "    'Higher education',\n",
    "    'Incomplete higher',\n",
    "    'Lower secondary',\n",
    "    'Academic degree'\n",
    "]\n",
    "\n",
    "# Calculating total counts and counts with TARGET == 1 for each education type\n",
    "education_data = []\n",
    "for education in education_types:\n",
    "    total = app_train[app_train['NAME_EDUCATION_TYPE'] == education].shape[0]\n",
    "    defaults = app_train[(app_train['NAME_EDUCATION_TYPE'] == education) & (\n",
    "        app_train['TARGET'] == 1)].shape[0]\n",
    "    default_rate = (defaults / total) * 100 if total > 0 else 0\n",
    "    education_data.append((education, total, defaults, default_rate))\n",
    "\n",
    "# Sorting by total counts for the first plot\n",
    "education_data_sorted_by_total = sorted(education_data, key=lambda x: x[1])\n",
    "\n",
    "# Sorting by default rate for the second plot\n",
    "education_data_sorted_by_default_rate = sorted(\n",
    "    education_data, key=lambda x: x[3], reverse=False)\n",
    "\n",
    "# Splitting the data for plotting\n",
    "educations_sorted_by_total, _, _, _ = zip(*education_data_sorted_by_total)\n",
    "_, counts_sorted_by_total, _, percentages_sorted_by_total = zip(\n",
    "    *education_data_sorted_by_total)\n",
    "\n",
    "educations_sorted_by_default_rate, _, counts_sorted_by_default_rate, percentages_sorted_by_default_rate = zip(\n",
    "    *education_data_sorted_by_default_rate)\n",
    "\n",
    "# Creating subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés par Type d'éducation\", \"Taux de non-remboursement par Type d'éducation\"))\n",
    "\n",
    "# Adding traces for the first plot\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(educations_sorted_by_total), x=list(counts_sorted_by_total), orientation='h',\n",
    "           marker=dict(color=colors), text=[f\"{p:.2f}%\" for p in percentages_sorted_by_total]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Adding traces for the second plot, with a different order based on default rate\n",
    "fig.add_trace(\n",
    "    go.Bar(y=list(educations_sorted_by_default_rate), x=list(percentages_sorted_by_default_rate), orientation='h',\n",
    "           marker=dict(color=colors), text=[f\"{c} ({p:.2f}%)\" for c, p in zip(counts_sorted_by_default_rate, percentages_sorted_by_default_rate)]),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Updating the layout and displaying the plot\n",
    "fig.update_layout(height=600, width=1000,\n",
    "                  title_text=\"Représentation des prêts en fonction du Type d'éducation\", showlegend=False)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La majorité des clients ont une éducation dans l'éducation secondaire, suivis des clients avec une éducation supérieure. Un très petit nombre d'emprunteur possède un diplôme universitaire.\n",
    "\n",
    "La catégorie du premier cycle du secondaire, bien que rare, a le taux le plus élevé de non-remboursement du prêt (11%). Les personnes ayant un diplôme universitaire ont un taux de non-remboursement inférieur à 2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération d'une palette de couleurs\n",
    "colors = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896',\n",
    "          '#9467bd', '#c5b0d5', '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7',\n",
    "          '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "# Liste des types de logement\n",
    "housing_types = [\n",
    "    'House / apartment', 'Rented apartment', 'With parents',\n",
    "    'Municipal apartment', 'Office apartment', 'Co-op apartment'\n",
    "]\n",
    "\n",
    "# Calcul des totaux et des pourcentages pour les cas avec TARGET == 1\n",
    "housing_data = []\n",
    "for housing in housing_types:\n",
    "    total_count = app_train[app_train['NAME_HOUSING_TYPE'] == housing].shape[0]\n",
    "    target_count = app_train[(app_train['NAME_HOUSING_TYPE'] == housing) & (\n",
    "        app_train['TARGET'] == 1)].shape[0]\n",
    "    percentage = (target_count / total_count) * 100 if total_count > 0 else 0\n",
    "    housing_data.append((housing, total_count, target_count, percentage))\n",
    "\n",
    "# Tri par le total pour le premier subplot\n",
    "housing_sorted_by_total = sorted(\n",
    "    housing_data, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# Tri par le pourcentage pour le second subplot\n",
    "housing_sorted_by_percentage = sorted(\n",
    "    housing_data, key=lambda x: x[3], reverse=False)\n",
    "\n",
    "# Création des subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés par Type de logement\", \"Taux de non-remboursement par Type de logement\"))\n",
    "\n",
    "# Ajout des traces pour le premier subplot\n",
    "for i, (housing, total_count, _, _) in enumerate(housing_sorted_by_total):\n",
    "    fig.add_trace(go.Bar(y=[housing], x=[total_count], orientation='h', marker=dict(color=colors[i % len(colors)])),\n",
    "                  row=1, col=1)\n",
    "\n",
    "# Ajout des traces pour le second subplot\n",
    "for i, (housing, _, _, percentage) in enumerate(housing_sorted_by_percentage):\n",
    "    fig.add_trace(go.Bar(y=[housing], x=[percentage], orientation='h', marker=dict(color=colors[i % len(colors)]), text=f\"{percentage:.2f}%\"),\n",
    "                  row=1, col=2)\n",
    "\n",
    "# Mise à jour de la disposition et affichage du graphique\n",
    "fig.update_layout(height=600, width=1000, showlegend=False,\n",
    "                  title_text=\"Représentation des prêts en fonction du Type de logement\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plus de 250 000 demandeurs de crédits vivent en maison ou appartement. Les catégories suivantes, faible pourcentage, représentent une population moins \"indépendante\" (vivre chez ses parents, etc…).\n",
    "\n",
    "Dans ces catégories, les loueurs d'appartements (non propriétaires de leur résidence principale), ainsi que ceux qui vivent chez leurs parents, ont un taux de non-remboursement supérieur à 10%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous avons traiter les outliers et les variables catégorielle. Nous allons voir les corrélations qu'il existe entre nos colonnes(Features) et notre TARGET pour évaluer les liens entre nos variables et choisir a features les plus pertinantes. Pour faire cela nous allons calculer le coefficient de corrélation de Person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find correlations with the target and sort\n",
    "correlations = app_train.corr(numeric_only=True)['TARGET'].sort_values()\n",
    "\n",
    "# Display correlations\n",
    "print('Most Positive Correlations:\\n', correlations.tail(15))\n",
    "print('\\nMost Negative Correlations:\\n', correlations.head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notons que la corrélation la plus forte est celle de la variable 'DAYS_BIRTH'. Ceci étant, pour faciliter la compréhension est retrouver la logique vue en préambule, les jours exprimés en valeurs négatives peuvent être traités en valeurs absolues. Alors le coef. de Person sera négatif, cela expose le fait qu'un client plus âgé sera moins susceptible de faire défaut au remboursement de son crédit (cela peut sembler logique, en tout cas ce n'est pas absurde)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the correlation of the positive days since birth and target\n",
    "app_train['DAYS_BIRTH'] = abs(app_train['DAYS_BIRTH'])\n",
    "app_train['DAYS_BIRTH'].corr(app_train['TARGET'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En termes de distribution des âges elle peut uniquement servir à visualiser la non présence d'outliers, suite à ce qui a été fait en amont sur les valeurs négatives de départ. Pour visualiser l'effet de l'âge sur la Target, nous pouvons faire un graphique (KDE) coloré par la valeur TARGET 0 et 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'âge en années\n",
    "ages_years = app_train['DAYS_BIRTH'] / 365\n",
    "\n",
    "# Création du graphique\n",
    "fig = go.Figure()\n",
    "\n",
    "# Ajout d'un histogramme à la figure\n",
    "fig.add_trace(go.Histogram(\n",
    "    x=ages_years, nbinsx=50,\n",
    "    marker=dict(line=dict(color='black', width=1))\n",
    "))\n",
    "\n",
    "# Mise à jour du layout pour ajouter les titres et personnaliser l'apparence\n",
    "fig.update_layout(\n",
    "    title_text='Age des clients',\n",
    "    xaxis_title_text='Age (Année)',\n",
    "    yaxis_title_text='Nombres',\n",
    "    bargap=0.2,  # Espace entre les barres de l'histogramme\n",
    "    template='plotly_white'  # Utilise un fond blanc pour le style\n",
    ")\n",
    "\n",
    "# Affichage du graphique\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcul de l'âge en années\n",
    "age_paid = app_train.loc[app_train['TARGET'] == 0, 'DAYS_BIRTH'] / 365\n",
    "age_not_paid = app_train.loc[app_train['TARGET'] == 1, 'DAYS_BIRTH'] / 365\n",
    "\n",
    "# Création d'une liste de données\n",
    "hist_data = [age_paid, age_not_paid]\n",
    "\n",
    "# Étiquettes pour les groupes de données\n",
    "group_labels = ['target == 0', 'target == 1']\n",
    "\n",
    "# Création du KDE plot\n",
    "fig = ff.create_distplot(hist_data, group_labels,\n",
    "                         show_hist=False, show_rug=False)\n",
    "\n",
    "# Ajout du titre et des étiquettes des axes\n",
    "fig.update_layout(title_text='Distribution des Ages',\n",
    "                  xaxis_title='Age (Année)',\n",
    "                  yaxis_title='Densité')\n",
    "\n",
    "# Affichage du graphique\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La courbe cible TARGET 1 s'incline vers l'extrémité la plus jeune de la plage. Bien qu'il ne s'agisse pas d'une corrélation significative (coefficient Pearson -0,07), cette variable sera probablement utile dans un modèle d'apprentissage car elle affecte la Target.\n",
    "essayons maintenant de regrouper les âges pour avoir un graphique plus précis sur taux de non-recouvrement des prêts en fonction de l'âge. Pour cela nous allons regrouper les âges présent par tranche de 5 ans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age information into a separate dataframe\n",
    "age_data = app_train[['TARGET', 'DAYS_BIRTH']]\n",
    "age_data['YEARS_BIRTH'] = age_data['DAYS_BIRTH'] / 365\n",
    "\n",
    "# Bin the age data\n",
    "age_data['YEARS_BINNED'] = pd.cut(\n",
    "    age_data['YEARS_BIRTH'], bins=np.linspace(20, 70, num=11))\n",
    "age_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by the bin and calculate averages\n",
    "age_groups = age_data.groupby('YEARS_BINNED').mean()\n",
    "age_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création du graphique de barres\n",
    "fig = go.Figure()\n",
    "\n",
    "# Ajout des barres pour chaque groupe d'âge\n",
    "fig.add_trace(go.Bar(\n",
    "    # Conversion de l'index en chaîne de caractères pour l'affichage\n",
    "    x=age_groups.index.astype(str),\n",
    "    # Calcul du pourcentage d'échec de remboursement\n",
    "    y=100 * age_groups['TARGET'],\n",
    "    marker=dict(line=dict(color='black', width=1))\n",
    "))\n",
    "\n",
    "# Mise à jour du layout pour ajouter les titres et personnaliser l'apparence\n",
    "fig.update_layout(\n",
    "    title_text=\"Non-remboursement d'un prêt par groupe d'âge\",\n",
    "    xaxis_title='Groupe âge (Années)',\n",
    "    yaxis_title='Taux de non-remboursement (%)',\n",
    "    xaxis_tickangle=-45,  # Rotation des étiquettes sur l'axe des x\n",
    "    template='plotly_white'  # Utilisation d'un fond blanc pour le style\n",
    ")\n",
    "\n",
    "# Affichage du graphique\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On vois que la tendance est bien réelle et décroissante en fonction de l'âge, le groupe d'âge des 20-25 ans on 12% de chance de ne pas rembourser leurs prêts contre 4% pour les 65-70 ans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sources extérieurs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces 3 variables (EXT_SOURCE) présentant les corrélations négatives les plus fortes avec la Target. Selon la documentation, ces fonctionnalités représentent un «score normalisé à partir d'une source de données externe». Difficile de comprendre le sens exact, nous pouvons émettre l'hypothèse d'une cote de crédit cumulative établie à l'aide de différentes sources de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de la matrice de corrélations pour les variables spécifiées\n",
    "corr_matrix = app_train[[\n",
    "    'TARGET', 'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH']].corr()\n",
    "\n",
    "# Création du graphique de heatmap\n",
    "fig = go.Figure(data=go.Heatmap(\n",
    "    z=corr_matrix.values,  # Valeurs de corrélation\n",
    "    x=corr_matrix.columns,  # Noms des colonnes pour l'axe des x\n",
    "    y=corr_matrix.index,  # Noms des lignes pour l'axe des y\n",
    "    colorscale='RdBu_r',  # Palette de couleurs\n",
    "    zmin=-0.25,  # Minimum de l'échelle de couleurs\n",
    "    zmax=0.6,  # Maximum de l'échelle de couleurs\n",
    "))\n",
    "\n",
    "# Ajout des annotations pour chaque cellule\n",
    "for i, row in enumerate(corr_matrix.values):\n",
    "    for j, value in enumerate(row):\n",
    "        fig.add_annotation(x=corr_matrix.columns[j], y=corr_matrix.index[i],\n",
    "                           text=str(round(value, 2)),\n",
    "                           showarrow=False, font=dict(color=\"black\"))\n",
    "\n",
    "# Mise à jour des titres et du layout\n",
    "fig.update_layout(\n",
    "    title_text='EXT_SOURCE Correlation Heatmap',\n",
    "    title_x=0.5,  # Centrer le titre\n",
    "    # Positionnement des labels de l'axe des x en haut\n",
    "    xaxis=dict(tickmode='array', side='top'),\n",
    "    # Inversion de l'axe des y pour correspondre à l'ordre habituel des heatmaps\n",
    "    yaxis=dict(tickmode='array', autorange='reversed'),\n",
    "    template='plotly_white'\n",
    ")\n",
    "\n",
    "# Affichage de la heatmap\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces sources extérieures sont corrélées négativement avec la Target (Attention, négativement mais avec de très faibles coefficients). Malgré tout, on peut penser que si la valeur augmente, le client est plus susceptible de pouvoir rembourser le crédit. Notons que 'DAYS_BIRTH' est corrélée avec 'EXT_SOURCE_1', peut-être l'un des facteurs de ce score est l'âge du client.<br>\n",
    "Visualisons maintenant la distribution de ces feature en fonction de TARGET."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare subplot figure with 3 rows\n",
    "fig = make_subplots(rows=3, cols=1, subplot_titles=['Distribution de EXT_SOURCE_1 par Valeur de TARGET',\n",
    "                                                    'Distribution de EXT_SOURCE_2 par Valeur de TARGET',\n",
    "                                                    'Distribution de EXT_SOURCE_3 par Valeur de TARGET'])\n",
    "\n",
    "# Iterate through the sources\n",
    "for i, source in enumerate(['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3']):\n",
    "    # Data for repaid loans and loans that were not repaid\n",
    "    data_repaid = app_train.loc[app_train['TARGET'] == 0, source].dropna()\n",
    "    data_not_repaid = app_train.loc[app_train['TARGET'] == 1, source].dropna()\n",
    "\n",
    "    # Create distplot for each source\n",
    "    # Note: ff.create_distplot returns a figure object which we need to deconstruct to use in subplots\n",
    "    fig_repaid = ff.create_distplot(\n",
    "        [data_repaid], ['Repaid'], show_hist=False, show_rug=False)\n",
    "    fig_not_repaid = ff.create_distplot(\n",
    "        [data_not_repaid], ['Not Repaid'], show_hist=False, show_rug=False)\n",
    "\n",
    "    # Adding traces from created distplots to the main subplot figure\n",
    "    for trace in fig_repaid['data']:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            trace, line=dict(color='blue')), row=i+1, col=1)\n",
    "    for trace in fig_not_repaid['data']:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            trace, line=dict(color='red')), row=i+1, col=1)\n",
    "\n",
    "# Update layout of the subplot figure\n",
    "fig.update_layout(height=1200, width=800, title_text=\"Distributions de EXT_SOURCE par Valeur de TARGET\",\n",
    "                  showlegend=False)\n",
    "\n",
    "# Show figure\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse Exploratoire des autres fichiers CSV\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons analyser les autres fichier présent dans notre jeu de données pour pouvoir ajouter de nouvelles features pertinentes pour notre modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse exploratoire fichier *bureau.csv*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce fichier contient tous les crédits antérieurs des clients fournis par d'autres institutions financières qui ont été déclarés au Bureau de crédit (pour les clients qui ont un prêt dans l'échantillon). Pour chaque prêt de l'échantillon, il y a autant de lignes que de nombre de crédits que le client avait au bureau de crédit avant la date de la demande.\n",
    "On va fusion le dataframe app_train avec bureau pour avoir les \"Target\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_bureau_train = app_train.merge(\n",
    "    bureau, left_on='SK_ID_CURR', right_on='SK_ID_CURR', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(application_bureau_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération d'une palette de couleurs\n",
    "colors = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896',\n",
    "          '#9467bd', '#c5b0d5', '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7',\n",
    "          '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "# Liste des statuts de crédit actifs\n",
    "credit_active_statuses = ['Closed', 'Active', 'Sold', 'Bad debt']\n",
    "\n",
    "# Calcul des totaux et des pourcentages pour les cas avec TARGET == 1\n",
    "credit_active_data = []\n",
    "for status in credit_active_statuses:\n",
    "    total_count = application_bureau_train[application_bureau_train['CREDIT_ACTIVE']\n",
    "                                           == status].shape[0]\n",
    "    target_count = application_bureau_train[(application_bureau_train['CREDIT_ACTIVE'] == status) & (\n",
    "        application_bureau_train['TARGET'] == 1)].shape[0]\n",
    "    percentage = (target_count / total_count) * 100 if total_count > 0 else 0\n",
    "    credit_active_data.append((status, total_count, target_count, percentage))\n",
    "\n",
    "# Tri par le total pour le premier subplot\n",
    "credit_active_sorted_by_total = sorted(\n",
    "    credit_active_data, key=lambda x: x[1], reverse=False)\n",
    "\n",
    "# Tri par le pourcentage pour le second subplot\n",
    "credit_active_sorted_by_percentage = sorted(\n",
    "    credit_active_data, key=lambda x: x[3], reverse=False)\n",
    "\n",
    "# Création des subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    \"Prêts accordés par Statut Actif\", \"Taux de non-remboursement par Statut Actif\"))\n",
    "\n",
    "# Ajout des traces pour le premier subplot\n",
    "for i, (status, total_count, _, _) in enumerate(credit_active_sorted_by_total):\n",
    "    fig.add_trace(go.Bar(y=[status], x=[total_count], orientation='h', marker=dict(color=colors[i]),\n",
    "                  text=f\"{total_count}\"),\n",
    "                  row=1, col=1)\n",
    "\n",
    "# Ajout des traces pour le second subplot\n",
    "for i, (status, _, _, percentage) in enumerate(credit_active_sorted_by_percentage):\n",
    "    fig.add_trace(go.Bar(y=[status], x=[percentage], orientation='h', marker=dict(color=colors[i]),\n",
    "                  text=f\"{percentage:.2f}%\"),\n",
    "                  row=1, col=2)\n",
    "\n",
    "# Mise à jour de la disposition et affichage du graphique\n",
    "fig.update_layout(height=600, width=1200, showlegend=False,\n",
    "                  title_text=\"Représentation des prêts en fonction du Statut Actif\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyse exploratoire fichier *Previous application data*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"previous_application\" contient des informations sur toutes les demandes précédentes de crédit immobilier des clients qui ont des prêts dans l'échantillon. Il y a une ligne pour chaque demande précédente liée aux prêts dans notre échantillon de données. SK_ID_CURR est la clé reliant les données application_train | test aux données previous_application.\n",
    "\n",
    "Il est nécessaire de fusionner \"application_train\" avec \"previous_application\" pour pour pouvoir extraire la part de TARGET == 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_prev_train = app_train.merge(\n",
    "    previous_application, left_on='SK_ID_CURR', right_on='SK_ID_CURR', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération d'une palette de couleurs\n",
    "colors = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896',\n",
    "          '#9467bd', '#c5b0d5', '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7',\n",
    "          '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "# Liste des types de contrat\n",
    "contract_types = ['Consumer loans', 'Cash loans', 'Revolving loans', 'XNA']\n",
    "\n",
    "# Initialisation des listes pour stocker les totaux et les pourcentages\n",
    "total_counts = []\n",
    "percentages_total = []\n",
    "target_1_counts = []\n",
    "percentages_target_1 = []\n",
    "\n",
    "# Calcul des totaux pour chaque type de contrat\n",
    "for contract in contract_types:\n",
    "    total_count = application_prev_train[application_prev_train['NAME_CONTRACT_TYPE_y']\n",
    "                                         == contract].shape[0]\n",
    "    target_count = application_prev_train[(application_prev_train['NAME_CONTRACT_TYPE_y'] == contract) &\n",
    "                                          (application_prev_train['TARGET'] == 1)].shape[0]\n",
    "    total_counts.append(total_count)\n",
    "    target_1_counts.append(target_count)\n",
    "\n",
    "# Calcul des pourcentages pour les deux graphiques\n",
    "total_sum = sum(total_counts)\n",
    "target_1_sum = sum(target_1_counts)\n",
    "percentages_total = [(count / total_sum) * 100 for count in total_counts]\n",
    "percentages_target_1 = [(count / target_1_sum) *\n",
    "                        100 for count in target_1_counts]\n",
    "\n",
    "# Tri des données par ordre croissant pour les deux graphiques\n",
    "sorted_indices_total = sorted(\n",
    "    range(len(total_counts)), key=lambda k: total_counts[k])\n",
    "sorted_indices_target_1 = sorted(\n",
    "    range(len(target_1_counts)), key=lambda k: target_1_counts[k])\n",
    "\n",
    "# Création des subplots\n",
    "fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "    'Prêts accordés par Type de Contrat', 'Taux de non-remboursement par Type de Contrat'))\n",
    "\n",
    "# Ajout des traces pour le premier graphique (totaux)\n",
    "fig.add_trace(\n",
    "    go.Bar(y=[contract_types[i] for i in sorted_indices_total],\n",
    "           x=[total_counts[i] for i in sorted_indices_total],\n",
    "           orientation='h',\n",
    "           marker=dict(color=colors),\n",
    "           text=[f\"{percentages_total[i]:.2f}%\" for i in sorted_indices_total]),\n",
    "    row=1, col=1\n",
    ")\n",
    "\n",
    "# Ajout des traces pour le second graphique (pourcentages)\n",
    "fig.add_trace(\n",
    "    go.Bar(y=[contract_types[i] for i in sorted_indices_target_1],\n",
    "           x=[target_1_counts[i] for i in sorted_indices_target_1],\n",
    "           orientation='h',\n",
    "           marker=dict(color=colors),\n",
    "           text=[f\"{percentages_target_1[i]:.2f}%\" for i in sorted_indices_target_1]),\n",
    "    row=1, col=2\n",
    ")\n",
    "\n",
    "# Mise à jour de la mise en page et affichage du graphique\n",
    "fig.update_layout(height=600, width=1200, showlegend=False,\n",
    "                  title_text=\"Représentation des prêts en fonction du Type de Contrat\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_prev_train['NAME_CLIENT_TYPE'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_bar_charts(df, column_name, target_column='TARGET'):\n",
    "    # Define a color palette\n",
    "    colors = ['#1f77b4', '#aec7e8', '#ff7f0e', '#ffbb78', '#2ca02c', '#98df8a', '#d62728', '#ff9896',\n",
    "              '#9467bd', '#c5b0d5', '#8c564b', '#c49c94', '#e377c2', '#f7b6d2', '#7f7f7f', '#c7c7c7',\n",
    "              '#bcbd22', '#dbdb8d', '#17becf', '#9edae5']\n",
    "\n",
    "    # Extract the unique values from the specified column\n",
    "    unique_values = df[column_name].dropna().unique().tolist()\n",
    "\n",
    "    # Calculate total counts and target == 1 counts\n",
    "    total_counts = df[column_name].value_counts().reindex(\n",
    "        unique_values).fillna(0)\n",
    "    target_counts = df[df[target_column] == 1][column_name].value_counts().reindex(\n",
    "        unique_values).fillna(0)\n",
    "    # Calculate percentage for fist plot\n",
    "    # percentage_total = (total_count)\n",
    "    # Calculate percentages of non-repayment for the second plot\n",
    "    percentages_target = (target_counts / total_counts) * 100\n",
    "    # Calculate the percentage of each category in terms of the total number of observations\n",
    "    total_percentages = (total_counts / total_counts.sum()) * 100\n",
    "    # Sort the data for plotting\n",
    "    total_counts_sorted = total_counts.sort_values(ascending=True)\n",
    "    percentages_target_sorted = percentages_target.sort_values(ascending=True)\n",
    "\n",
    "    # Create the subplot figure\n",
    "    fig = make_subplots(rows=1, cols=2, subplot_titles=(\n",
    "        f\"Total number of {column_name}\", f\"Percentage of non-repayment for {column_name}\"))\n",
    "\n",
    "    for i, (value, percentage) in enumerate(total_counts_sorted.items()):\n",
    "        count = total_counts[value]\n",
    "        percentage = total_percentages[value]\n",
    "        fig.add_trace(\n",
    "            go.Bar(y=[value], x=[count], orientation='h', marker=dict(color=colors[i % len(colors)]),\n",
    "                   text=f\"{percentage:.2f}%\"),\n",
    "            row=1, col=1\n",
    "        )\n",
    "\n",
    "    for i, (value, percentage) in enumerate(percentages_target_sorted.items()):\n",
    "        fig.add_trace(\n",
    "            go.Bar(y=[value], x=[percentage], orientation='h', marker=dict(color=colors[i % len(colors)]), name=f\"Percentage {value}\",\n",
    "                   text=f\"{percentage:.2f}%\"),\n",
    "            row=1, col=2\n",
    "        )\n",
    "\n",
    "    # Update the layout and display the figure\n",
    "    fig.update_layout(height=600, width=1200, showlegend=False,\n",
    "                      title_text=f\"Comparison of {column_name}\")\n",
    "    fig.update_traces(textposition='outside')\n",
    "\n",
    "    fig.show()\n",
    "\n",
    "\n",
    "# Example usage of the function\n",
    "create_comparison_bar_charts(application_prev_train, 'NAME_CONTRACT_TYPE_y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maintenant que nous aovns analyser les différents qui compose nos données nous allons aggréger ces données dans un seul et même dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a simple dataset with the train / test merge app\n",
    "data = pd.concat([app_test, app_train], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:(48744, 121)\n",
      "Test:(307511, 122)\n",
      ">>> Data:(356255, 122)\n"
     ]
    }
   ],
   "source": [
    "# Check data\n",
    "print('Train:' + str(app_test.shape))\n",
    "print('Test:' + str(app_train.shape))\n",
    "print('>>> Data:' + str(data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48744"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data.SK_ID_CURR[data.TARGET.isna()] ==\n",
    "    app_test.SK_ID_CURR)  # all is good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "A partir du fichier bureau.csv, il est possible d'extraire un historique sur les précédents crédits enregistrés par les clients. Il peut donc être intéressant d'enrichir l'échantillon avec ce type de données."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bureau.head())\n",
    "display(bureau.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>PREVIOUS_LOANS_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  PREVIOUS_LOANS_COUNT\n",
       "0      100001                     7\n",
       "1      100002                     8\n",
       "2      100003                     4\n",
       "3      100004                     2\n",
       "4      100005                     3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Total number of previous credits taken by each customer\n",
    "previous_loan_counts = bureau.groupby('SK_ID_CURR', as_index=False)['SK_ID_BUREAU'].count().rename(\n",
    "    columns={'SK_ID_BUREAU': 'PREVIOUS_LOANS_COUNT'})\n",
    "previous_loan_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 123)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge this new column in our data sample\n",
    "data = data.merge(previous_loan_counts, on='SK_ID_CURR', how='left')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "bureau_balance : bureau_balance.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(bureau_balance.head())\n",
    "display(bureau_balance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_BUREAU</th>\n",
       "      <th>MONTHS_BALANCE_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5001709</td>\n",
       "      <td>-48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5001710</td>\n",
       "      <td>-41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5001711</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5001712</td>\n",
       "      <td>-9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5001713</td>\n",
       "      <td>-10.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_BUREAU  MONTHS_BALANCE_MEAN\n",
       "0       5001709                -48.0\n",
       "1       5001710                -41.0\n",
       "2       5001711                 -1.5\n",
       "3       5001712                 -9.0\n",
       "4       5001713                -10.5"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Monthly average balances of previous credits in Credit Bureau.\n",
    "bureau_bal_mean = bureau_balance.groupby('SK_ID_BUREAU', as_index=False)[\n",
    "    'MONTHS_BALANCE'].mean().rename(columns={'MONTHS_BALANCE': 'MONTHS_BALANCE_MEAN'})\n",
    "bureau_bal_mean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>CREDIT_ACTIVE</th>\n",
       "      <th>CREDIT_CURRENCY</th>\n",
       "      <th>DAYS_CREDIT</th>\n",
       "      <th>CREDIT_DAY_OVERDUE</th>\n",
       "      <th>DAYS_CREDIT_ENDDATE</th>\n",
       "      <th>DAYS_ENDDATE_FACT</th>\n",
       "      <th>AMT_CREDIT_MAX_OVERDUE</th>\n",
       "      <th>CNT_CREDIT_PROLONG</th>\n",
       "      <th>AMT_CREDIT_SUM</th>\n",
       "      <th>AMT_CREDIT_SUM_DEBT</th>\n",
       "      <th>AMT_CREDIT_SUM_LIMIT</th>\n",
       "      <th>AMT_CREDIT_SUM_OVERDUE</th>\n",
       "      <th>CREDIT_TYPE</th>\n",
       "      <th>DAYS_CREDIT_UPDATE</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>MONTHS_BALANCE_MEAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>215354</td>\n",
       "      <td>Closed</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-497</td>\n",
       "      <td>0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>-153.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>91323.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>-131</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>215354</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-208</td>\n",
       "      <td>0</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>171342.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>215354</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-203</td>\n",
       "      <td>0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>464323.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>215354</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-203</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Credit card</td>\n",
       "      <td>-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>215354</td>\n",
       "      <td>Active</td>\n",
       "      <td>currency 1</td>\n",
       "      <td>-629</td>\n",
       "      <td>0</td>\n",
       "      <td>1197.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>77674.5</td>\n",
       "      <td>0</td>\n",
       "      <td>2700000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Consumer credit</td>\n",
       "      <td>-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR CREDIT_ACTIVE CREDIT_CURRENCY  DAYS_CREDIT  CREDIT_DAY_OVERDUE  \\\n",
       "0      215354        Closed      currency 1         -497                   0   \n",
       "1      215354        Active      currency 1         -208                   0   \n",
       "2      215354        Active      currency 1         -203                   0   \n",
       "3      215354        Active      currency 1         -203                   0   \n",
       "4      215354        Active      currency 1         -629                   0   \n",
       "\n",
       "   DAYS_CREDIT_ENDDATE  DAYS_ENDDATE_FACT  AMT_CREDIT_MAX_OVERDUE  \\\n",
       "0               -153.0             -153.0                     NaN   \n",
       "1               1075.0                NaN                     NaN   \n",
       "2                528.0                NaN                     NaN   \n",
       "3                  NaN                NaN                     NaN   \n",
       "4               1197.0                NaN                 77674.5   \n",
       "\n",
       "   CNT_CREDIT_PROLONG  AMT_CREDIT_SUM  AMT_CREDIT_SUM_DEBT  \\\n",
       "0                   0         91323.0                  0.0   \n",
       "1                   0        225000.0             171342.0   \n",
       "2                   0        464323.5                  NaN   \n",
       "3                   0         90000.0                  NaN   \n",
       "4                   0       2700000.0                  NaN   \n",
       "\n",
       "   AMT_CREDIT_SUM_LIMIT  AMT_CREDIT_SUM_OVERDUE      CREDIT_TYPE  \\\n",
       "0                   NaN                     0.0  Consumer credit   \n",
       "1                   NaN                     0.0      Credit card   \n",
       "2                   NaN                     0.0  Consumer credit   \n",
       "3                   NaN                     0.0      Credit card   \n",
       "4                   NaN                     0.0  Consumer credit   \n",
       "\n",
       "   DAYS_CREDIT_UPDATE  AMT_ANNUITY  MONTHS_BALANCE_MEAN  \n",
       "0                -131          NaN                  NaN  \n",
       "1                 -20          NaN                  NaN  \n",
       "2                 -16          NaN                  NaN  \n",
       "3                 -16          NaN                  NaN  \n",
       "4                 -21          NaN                  NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1716428, 17)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "bureau_full = bureau.merge(bureau_bal_mean, on='SK_ID_BUREAU', how='left')\n",
    "bureau_full.drop('SK_ID_BUREAU', axis=1, inplace=True)\n",
    "display(bureau_full.head())\n",
    "display(bureau_full.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "bureau_mean = bureau_full.select_dtypes(include=[np.number]).groupby(\n",
    "    'SK_ID_CURR', as_index=False).mean().add_prefix('PREV_BUR_MEAN_')\n",
    "bureau_mean = bureau_mean.rename(\n",
    "    columns={'PREV_BUR_MEAN_SK_ID_CURR': 'SK_ID_CURR'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 136)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge all this features with our data sample\n",
    "data = data.merge(bureau_mean, on='SK_ID_CURR', how='left')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous_application\n",
    "\n",
    "Vérification des valeurs de 'SK_ID_CURR' entre data et previous_application…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(previous_application.head())\n",
    "display(previous_application.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check\n",
    "len(previous_application.SK_ID_CURR.isin(\n",
    "    data.SK_ID_CURR)) == len(previous_application)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>PREVIOUS_APPLICATION_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100002</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100003</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100004</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100005</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  PREVIOUS_APPLICATION_COUNT\n",
       "0      100001                           1\n",
       "1      100002                           1\n",
       "2      100003                           3\n",
       "3      100004                           1\n",
       "4      100005                           2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of previous applications of the clients to Home Credit\n",
    "previous_application_counts = previous_application.groupby('SK_ID_CURR',\n",
    "                                                           as_index=False)['SK_ID_PREV'].count().rename(\n",
    "    columns={'SK_ID_PREV': 'PREVIOUS_APPLICATION_COUNT'})\n",
    "previous_application_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(356255, 137)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge this new column in our data sample\n",
    "data = data.merge(previous_application_counts, on='SK_ID_CURR', how='left')\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "credit_card_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(credit_card_balance.head())\n",
    "display(credit_card_balance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance.drop('SK_ID_CURR', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_card_balance_mean = credit_card_balance.groupby(\n",
    "    'SK_ID_PREV', as_index=False).mean(numeric_only=True).add_prefix('CARD_MEAN_')\n",
    "credit_card_balance_mean.rename(\n",
    "    columns={'CARD_MEAN_SK_ID_PREV': 'SK_ID_PREV'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670214, 57)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with previous_application\n",
    "previous_application = previous_application.merge(\n",
    "    credit_card_balance_mean, on='SK_ID_PREV', how='left')\n",
    "previous_application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "installments_payments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(installments_payments.head())\n",
    "display(installments_payments.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "installments_payments.drop('SK_ID_CURR', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997752, 7)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "install_pay_mean = installments_payments.groupby(\n",
    "    'SK_ID_PREV', as_index=False).mean().add_prefix('INSTALL_MEAN_')\n",
    "install_pay_mean.rename(\n",
    "    columns={'INSTALL_MEAN_SK_ID_PREV': 'SK_ID_PREV'}, inplace=True)\n",
    "install_pay_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670214, 63)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with previous_application\n",
    "previous_application = previous_application.merge(\n",
    "    install_pay_mean, on='SK_ID_PREV', how='left')\n",
    "previous_application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POS_CASH_balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(pos_cash_balance.head())\n",
    "display(pos_cash_balance.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_cash_balance.drop('SK_ID_CURR', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(997752, 7)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "POS_mean = installments_payments.groupby(\n",
    "    'SK_ID_PREV', as_index=False).mean().add_prefix('POS_MEAN_')\n",
    "POS_mean.rename(columns={'POS_MEAN_SK_ID_PREV': 'SK_ID_PREV'}, inplace=True)\n",
    "POS_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1670214, 69)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge with previous_application\n",
    "previous_application = previous_application.merge(\n",
    "    POS_mean, on='SK_ID_PREV', how='left')\n",
    "previous_application.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "previous_application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Retour sur previous_application pour assembles les lignes d'observation selon 'SK_ID_CURR'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(previous_application.head())\n",
    "display(previous_application.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_appl_mean = previous_application.groupby('SK_ID_CURR', as_index=False).mean(\n",
    "    numeric_only=True).add_prefix('PREV_APPL_MEAN_')\n",
    "prev_appl_mean.rename(\n",
    "    columns={'PREV_APPL_MEAN_SK_ID_CURR': 'SK_ID_CURR'}, inplace=True)\n",
    "prev_appl_mean = prev_appl_mean.drop('PREV_APPL_MEAN_SK_ID_PREV', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(prev_appl_mean.head())\n",
    "display(prev_appl_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reminder…\n",
    "print('data shape', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>NAME_CONTRACT_TYPE</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>PREV_APPL_MEAN_INSTALL_MEAN_DAYS_INSTALMENT</th>\n",
       "      <th>PREV_APPL_MEAN_INSTALL_MEAN_DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>PREV_APPL_MEAN_INSTALL_MEAN_AMT_INSTALMENT</th>\n",
       "      <th>PREV_APPL_MEAN_INSTALL_MEAN_AMT_PAYMENT</th>\n",
       "      <th>PREV_APPL_MEAN_POS_MEAN_NUM_INSTALMENT_VERSION</th>\n",
       "      <th>PREV_APPL_MEAN_POS_MEAN_NUM_INSTALMENT_NUMBER</th>\n",
       "      <th>PREV_APPL_MEAN_POS_MEAN_DAYS_INSTALMENT</th>\n",
       "      <th>PREV_APPL_MEAN_POS_MEAN_DAYS_ENTRY_PAYMENT</th>\n",
       "      <th>PREV_APPL_MEAN_POS_MEAN_AMT_INSTALMENT</th>\n",
       "      <th>PREV_APPL_MEAN_POS_MEAN_AMT_PAYMENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100001</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>568800.0</td>\n",
       "      <td>20560.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1664.000000</td>\n",
       "      <td>-1679.500000</td>\n",
       "      <td>7312.725000</td>\n",
       "      <td>7312.725000</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>-1664.000000</td>\n",
       "      <td>-1679.500000</td>\n",
       "      <td>7312.725000</td>\n",
       "      <td>7312.725000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100005</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>99000.0</td>\n",
       "      <td>222768.0</td>\n",
       "      <td>17370.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-586.000000</td>\n",
       "      <td>-609.555556</td>\n",
       "      <td>6240.205000</td>\n",
       "      <td>6240.205000</td>\n",
       "      <td>1.111111</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>-586.000000</td>\n",
       "      <td>-609.555556</td>\n",
       "      <td>6240.205000</td>\n",
       "      <td>6240.205000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100013</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>Y</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>663264.0</td>\n",
       "      <td>69777.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-854.833333</td>\n",
       "      <td>-867.592593</td>\n",
       "      <td>16349.077917</td>\n",
       "      <td>13702.794792</td>\n",
       "      <td>1.050926</td>\n",
       "      <td>6.027778</td>\n",
       "      <td>-854.833333</td>\n",
       "      <td>-867.592593</td>\n",
       "      <td>16349.077917</td>\n",
       "      <td>13702.794792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100028</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>F</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>2</td>\n",
       "      <td>315000.0</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>49018.5</td>\n",
       "      <td>1575000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-944.964286</td>\n",
       "      <td>-949.814286</td>\n",
       "      <td>7836.897982</td>\n",
       "      <td>7557.738339</td>\n",
       "      <td>1.038889</td>\n",
       "      <td>17.595238</td>\n",
       "      <td>-944.964286</td>\n",
       "      <td>-949.814286</td>\n",
       "      <td>7836.897982</td>\n",
       "      <td>7557.738339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100038</td>\n",
       "      <td>Cash loans</td>\n",
       "      <td>M</td>\n",
       "      <td>Y</td>\n",
       "      <td>N</td>\n",
       "      <td>1</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>32067.0</td>\n",
       "      <td>625500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-622.000000</td>\n",
       "      <td>-634.250000</td>\n",
       "      <td>11100.337500</td>\n",
       "      <td>11100.337500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.500000</td>\n",
       "      <td>-622.000000</td>\n",
       "      <td>-634.250000</td>\n",
       "      <td>11100.337500</td>\n",
       "      <td>11100.337500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 188 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR NAME_CONTRACT_TYPE CODE_GENDER FLAG_OWN_CAR FLAG_OWN_REALTY  \\\n",
       "0      100001         Cash loans           F            N               Y   \n",
       "1      100005         Cash loans           M            N               Y   \n",
       "2      100013         Cash loans           M            Y               Y   \n",
       "3      100028         Cash loans           F            N               Y   \n",
       "4      100038         Cash loans           M            Y               N   \n",
       "\n",
       "   CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0             0          135000.0    568800.0      20560.5         450000.0   \n",
       "1             0           99000.0    222768.0      17370.0         180000.0   \n",
       "2             0          202500.0    663264.0      69777.0         630000.0   \n",
       "3             2          315000.0   1575000.0      49018.5        1575000.0   \n",
       "4             1          180000.0    625500.0      32067.0         625500.0   \n",
       "\n",
       "   ... PREV_APPL_MEAN_INSTALL_MEAN_DAYS_INSTALMENT  \\\n",
       "0  ...                                -1664.000000   \n",
       "1  ...                                 -586.000000   \n",
       "2  ...                                 -854.833333   \n",
       "3  ...                                 -944.964286   \n",
       "4  ...                                 -622.000000   \n",
       "\n",
       "  PREV_APPL_MEAN_INSTALL_MEAN_DAYS_ENTRY_PAYMENT  \\\n",
       "0                                   -1679.500000   \n",
       "1                                    -609.555556   \n",
       "2                                    -867.592593   \n",
       "3                                    -949.814286   \n",
       "4                                    -634.250000   \n",
       "\n",
       "  PREV_APPL_MEAN_INSTALL_MEAN_AMT_INSTALMENT  \\\n",
       "0                                7312.725000   \n",
       "1                                6240.205000   \n",
       "2                               16349.077917   \n",
       "3                                7836.897982   \n",
       "4                               11100.337500   \n",
       "\n",
       "  PREV_APPL_MEAN_INSTALL_MEAN_AMT_PAYMENT  \\\n",
       "0                             7312.725000   \n",
       "1                             6240.205000   \n",
       "2                            13702.794792   \n",
       "3                             7557.738339   \n",
       "4                            11100.337500   \n",
       "\n",
       "  PREV_APPL_MEAN_POS_MEAN_NUM_INSTALMENT_VERSION  \\\n",
       "0                                       1.250000   \n",
       "1                                       1.111111   \n",
       "2                                       1.050926   \n",
       "3                                       1.038889   \n",
       "4                                       1.000000   \n",
       "\n",
       "   PREV_APPL_MEAN_POS_MEAN_NUM_INSTALMENT_NUMBER  \\\n",
       "0                                       2.500000   \n",
       "1                                       5.000000   \n",
       "2                                       6.027778   \n",
       "3                                      17.595238   \n",
       "4                                       6.500000   \n",
       "\n",
       "   PREV_APPL_MEAN_POS_MEAN_DAYS_INSTALMENT  \\\n",
       "0                             -1664.000000   \n",
       "1                              -586.000000   \n",
       "2                              -854.833333   \n",
       "3                              -944.964286   \n",
       "4                              -622.000000   \n",
       "\n",
       "   PREV_APPL_MEAN_POS_MEAN_DAYS_ENTRY_PAYMENT  \\\n",
       "0                                -1679.500000   \n",
       "1                                 -609.555556   \n",
       "2                                 -867.592593   \n",
       "3                                 -949.814286   \n",
       "4                                 -634.250000   \n",
       "\n",
       "   PREV_APPL_MEAN_POS_MEAN_AMT_INSTALMENT  PREV_APPL_MEAN_POS_MEAN_AMT_PAYMENT  \n",
       "0                             7312.725000                          7312.725000  \n",
       "1                             6240.205000                          6240.205000  \n",
       "2                            16349.077917                         13702.794792  \n",
       "3                             7836.897982                          7557.738339  \n",
       "4                            11100.337500                         11100.337500  \n",
       "\n",
       "[5 rows x 188 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(356255, 188)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Last merge with our data sample\n",
    "data = data.merge(prev_appl_mean, on='SK_ID_CURR', how='left')\n",
    "# data.set_index('SK_ID_CURR', inplace=True)\n",
    "display(data.head())\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature enginering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le \"feature engineering\" est le processus de transformation des données brutes en caractéristiques (features) utiles qui aident à améliorer la performance d'un modèle de machine learning. Les différents types incluent la création de variables (comme combiner des colonnes), la sélection de caractéristiques (choisir les variables les plus pertinentes), l'extraction de caractéristiques (comme l'analyse de composantes principales), et la transformation de variables (normalisation, standardisation, encodage de variables catégorielles)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**3 features extraites des précédentes étapes**\n",
    "\n",
    "Pour rappel, les étapes précédentes consistaient uniquement à établir des liens entre nos fichiers, des fusions de table dans le but d'enrichir l'échantillon de travail. Ceci étant, avant de procéder au merging des éléments, on a pu facilement extraire 3 variables de moyenne et de comptage.\n",
    "- PREVIOUS_LOANS_COUNT from bureau.csv: Nombre total des précédents crédits pris par chaque client\n",
    "- MONTHS_BALANCE_MEAN from bureau_balance.csv: Solde moyen mensuel des précédents crédits\n",
    "- PREVIOUS_APPLICATION_COUNT from previous_application.csv: Nombre de demandes antérieures des clients au crédit immobilier<br>\n",
    "\n",
    "**Création de 4 nouvelles variables métiers**\n",
    "\n",
    "Sans être expert en crédit bancaire, on peut assez facilement apporter quelques ratios explicatifs. D'autant plus qu'une veille parallèle permet de mieux comprendre les enjeux attendus. Voyons ci-dessous quelles features est-il pertinent d'intégrer.\n",
    "\n",
    "- CREDIT_INCOME_PERCENT: Pourcentage du montant du crédit par rapport au revenu d'un client\n",
    "- ANNUITY_INCOME_PERCENT: Pourcentage de la rente de prêt par rapport au revenu d'un client\n",
    "- CREDIT_TERM: Durée du paiement en mois\n",
    "- DAYS_EMPLOYED_PERCENT: Pourcentage des jours employés par rapport à l'âge du client\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features domaines métier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sans être expert en crédit bancaire, on peut assez facilement apporter quelques ratios explicatifs. D'autant plus qu'une veille parallèle permet de mieux comprendre les enjeux attendus. Voyons ci-dessous quelles features est-il pertinent d'intégrer.\n",
    "\n",
    "- CREDIT_INCOME_PERCENT: Pourcentage du montant du crédit par rapport au revenu d'un client\n",
    "- ANNUITY_INCOME_PERCENT: Pourcentage de la rente de prêt par rapport au revenu d'un client\n",
    "- CREDIT_TERM: Durée du paiement en mois\n",
    "- DAYS_EMPLOYED_PERCENT: Pourcentage des jours employés par rapport à l'âge du client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before…\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['CREDIT_INCOME_PERCENT'] = data['AMT_CREDIT'] / data['AMT_INCOME_TOTAL']\n",
    "data['ANNUITY_INCOME_PERCENT'] = data['AMT_ANNUITY'] / data['AMT_INCOME_TOTAL']\n",
    "data['CREDIT_TERM'] = data['AMT_ANNUITY'] / data['AMT_CREDIT']\n",
    "data['DAYS_EMPLOYED_PERCENT'] = data['DAYS_EMPLOYED'] / data['DAYS_BIRTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After…\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Variables from features engineering\n",
    "features_engin = ['PREVIOUS_LOANS_COUNT', 'MONTHS_BALANCE_MEAN', 'PREVIOUS_APPLICATION_COUNT',\n",
    "                  'CREDIT_INCOME_PERCENT', 'ANNUITY_INCOME_PERCENT', 'CREDIT_TERM', 'DAYS_EMPLOYED_PERCENT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display correlations with features engineering\n",
    "print('Most Positive Correlations:\\n', data.corr(numeric_only=True)\n",
    "      ['TARGET'].sort_values().tail(15))\n",
    "print(\"--------------------------\")\n",
    "print('Most Negative Correlations:\\n', data.corr(numeric_only=True)\n",
    "      ['TARGET'].sort_values().head(15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Make a new dataframe for polynomial features\n",
    "\n",
    "poly_features = data[[\n",
    "    'EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH', 'TARGET']]\n",
    "\n",
    "\n",
    "# imputer for handling missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "\n",
    "poly_target = poly_features['TARGET']\n",
    "\n",
    "poly_features = poly_features.drop(columns=['TARGET'])\n",
    "\n",
    "# Need to impute missing values\n",
    "poly_features = imputer.fit_transform(poly_features)\n",
    "poly_features_test = imputer.transform(poly_features_test)\n",
    "\n",
    "\n",
    "# Create the polynomial object with specified degree\n",
    "poly_transformer = PolynomialFeatures(degree=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the polynomial features\n",
    "poly_transformer.fit(poly_features)\n",
    "\n",
    "# Transform the features\n",
    "poly_features = poly_transformer.transform(poly_features)\n",
    "poly_features_test = poly_transformer.transform(poly_features_test)\n",
    "print('Polynomial Features shape: ', poly_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "poly_transformer.get_feature_names_out(\n",
    "    input_features=['EXT_SOURCE_1', 'EXT_SOURCE_2', 'EXT_SOURCE_3', 'DAYS_BIRTH'])[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Create a dataframe of the features\n",
    "poly_features = pd.DataFrame(poly_features,\n",
    "                             columns=poly_transformer.get_feature_names_out(['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
    "                                                                             'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Add in the target\n",
    "poly_features['TARGET'] = poly_target\n",
    "\n",
    "# Find the correlations with the target\n",
    "poly_corrs = poly_features.corr()['TARGET'].sort_values()\n",
    "\n",
    "# Display most negative and most positive\n",
    "print(poly_corrs.head(10))\n",
    "print(poly_corrs.tail(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put test features into dataframe\n",
    "poly_features_test = pd.DataFrame(poly_features_test,\n",
    "                                  columns=poly_transformer.get_feature_names_out(['EXT_SOURCE_1', 'EXT_SOURCE_2',\n",
    "                                                                                  'EXT_SOURCE_3', 'DAYS_BIRTH']))\n",
    "\n",
    "# Merge polynomial features into training dataframe\n",
    "poly_features['SK_ID_CURR'] = app_train['SK_ID_CURR']\n",
    "app_train_poly = app_train.merge(poly_features, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Merge polnomial features into testing dataframe\n",
    "poly_features_test['SK_ID_CURR'] = app_test['SK_ID_CURR']\n",
    "app_test_poly = app_test.merge(poly_features_test, on='SK_ID_CURR', how='left')\n",
    "\n",
    "# Align the dataframes\n",
    "app_train_poly, app_test_poly = app_train_poly.align(\n",
    "    app_test_poly, join='inner', axis=1)\n",
    "\n",
    "# Print out the new shapes\n",
    "print('Training data with polynomial features shape: ', app_train_poly.shape)\n",
    "print('Testing data with polynomial features shape:  ', app_test_poly.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il est nécessaire de commencer par la mise en place des données d'entrainement / test. On peut procéder en rappel avec les jeux de données application_train/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = data[data['SK_ID_CURR'].isin(app_train.SK_ID_CURR)]\n",
    "data_test = data[data['SK_ID_CURR'].isin(app_test.SK_ID_CURR)]\n",
    "\n",
    "data_test = data_test.drop('TARGET', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.set_index('SK_ID_CURR', inplace=True)\n",
    "data_test.set_index('SK_ID_CURR', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape with categorical columns:  (307511, 187)\n",
      "Testing Features shape with categorical columns:  (48744, 186)\n"
     ]
    }
   ],
   "source": [
    "print('Training Features shape with categorical columns: ', data_train.shape)\n",
    "print('Testing Features shape with categorical columns: ', data_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encodage des variables catégorielle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une modèle de machine learning n'est pas capable d'interpréter les variables catégorielle. Pour pouvoir les utiliser dans notre modèle on doit encoder ces variables en nombre.Il existe deux méthode pour transformer ces valeur, soit le _Label Encoding_ ou le _one-hot-encoding_.Pour les colonnes ayant seulement deux valeur unique nous utiliseront la méthode du Label Encoding et pour les autres le one-hot-encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Label Encoding et One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 colonnes ont été encodées:['NAME_CONTRACT_TYPE', 'FLAG_OWN_CAR', 'FLAG_OWN_REALTY']\n"
     ]
    }
   ],
   "source": [
    "# Create a label encoder object\n",
    "le = LabelEncoder()\n",
    "list_col_name = []\n",
    "le_count = 0\n",
    "\n",
    "# Iterate through the columns\n",
    "for col in app_train:\n",
    "    if app_train[col].dtype == 'object':\n",
    "        # If 2 or fewer unique categories\n",
    "        if len(list(app_train[col].unique())) <= 2:\n",
    "            list_col_name.append(col)\n",
    "            # Train on the training data\n",
    "            le.fit(app_train[col])\n",
    "            # Transform both training and testing data\n",
    "            app_train[col] = le.transform(app_train[col])\n",
    "            app_test[col] = le.transform(app_test[col])\n",
    "\n",
    "            # Keep track of how many columns were label encoded\n",
    "            le_count += 1\n",
    "\n",
    "print(f'{le_count} colonnes ont été encodées:{list_col_name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 243)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "# one-hot encoding of categorical variables\n",
    "app_train = pd.get_dummies(app_train)\n",
    "app_test = pd.get_dummies(app_test)\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignement des datasets train et test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le one-hot-encoding a créer plus de colonne dans le training data car certaines categories ne sont pas representer dans les données de test. Pour supprimer ces colonnes nous allons 'aligné' nos dataframes, tout en gardant la colonne 'TARGET' dans notre app_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Features shape:  (307511, 240)\n",
      "Testing Features shape:  (48744, 239)\n"
     ]
    }
   ],
   "source": [
    "train_labels = app_train['TARGET']\n",
    "\n",
    "# Align the training and testing data, keep only columns present in both dataframes\n",
    "app_train, app_test = app_train.align(app_test, join='inner', axis=1)\n",
    "\n",
    "# Add the target back in\n",
    "app_train['TARGET'] = train_labels\n",
    "\n",
    "print('Training Features shape: ', app_train.shape)\n",
    "print('Testing Features shape: ', app_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((307511, 187), (48744, 186))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Copy before imputation of missing values\n",
    "train = data_train.copy()\n",
    "test = data_test.copy()\n",
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imputation des valeurs manquantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant passé à l'imputation des valeurs manquantes dans notre jeu de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choix de la méthode d'imputation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour choisir la meilleurs méthode d'imputation nous avons sélectionner différentes méthode d'imputation (imputation par la moyenne,médiane,knn imputer). Pour ce test nous allons tester les modèles et évaluer grâce au MSE. On a choisi différents algorithme du plus complexe au plus simple pour voir si il y'a une amélioration significative. Pour ces test nous allons exécuter les mêmes test avec le même sample et de Cross Validation et la même metric d'évaluation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Imputation par le KNN Imputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the size of the data and convert types to save memory\n",
    "data_sample = app_train.sample(frac=0.1, random_state=42)\n",
    "for col in data_sample.columns:\n",
    "    if data_sample[col].dtype == np.float64:\n",
    "        data_sample[col] = data_sample[col].astype(np.float32)\n",
    "    if data_sample[col].dtype == np.int64:\n",
    "        data_sample[col] = data_sample[col].astype(np.int32)\n",
    "\n",
    "# Display the size of the sample\n",
    "print(f\"Sample size: {data_sample.shape}\")\n",
    "\n",
    "X = data_sample.drop('TARGET', axis=1)\n",
    "y = data_sample['TARGET']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Pipeline with KNNImputer and LinearRegression\n",
    "pipeline = Pipeline([\n",
    "    # Initial value for n_neighbors; will be adjusted by GridSearch\n",
    "    ('imputer', KNNImputer(n_neighbors=5)),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "# Parameters for GridSearchCV\n",
    "param_grid = {\n",
    "    # Extending the search range up to 15\n",
    "    'imputer__n_neighbors': list(range(3, 16))\n",
    "}\n",
    "\n",
    "# Setting up GridSearchCV and executing the Grid Search\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error', verbose=3)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best parameters found\n",
    "best_params = grid_search.best_params_\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Evaluation on the test set with the best model\n",
    "best_model = grid_search.best_estimator_\n",
    "predictions = best_model.predict(X_test)\n",
    "test_score = mean_squared_error(y_test, predictions)\n",
    "print(f\"MSE on the test set: {test_score}\")\n",
    "\n",
    "# Accessing cross-validation results for each parameter configuration\n",
    "cv_results = grid_search.cv_results_\n",
    "\n",
    "# Preparing the DataFrame to store the results\n",
    "results_df = pd.DataFrame(cv_results[\"params\"])\n",
    "for i in range(5):  # Assuming cv=5 as specified in GridSearchCV\n",
    "    results_df[f'MSE Fold {i+1}'] = -cv_results[f'split{i}_test_score']\n",
    "results_df['MSE Mean'] = -cv_results['mean_test_score']\n",
    "\n",
    "# Adding the best parameter and the MSE on the test set to the DataFrame\n",
    "results_df['Best Parameter'] = results_df['imputer__n_neighbors'] == best_params['imputer__n_neighbors']\n",
    "results_df.loc['Mean / Total'] = results_df.mean(numeric_only=True)\n",
    "results_df.at['Mean / Total', 'Best Parameter'] = test_score\n",
    "\n",
    "# Saving the results to a CSV file\n",
    "results_df.to_csv('grid_search_results.csv', index=False)\n",
    "\n",
    "print(\"Results saved in 'grid_search_results.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Résultats :<br>\n",
    "**Meilleurs paramètres:** {'imputer__n_neighbors': 5}<br>\n",
    "\n",
    "**MSE sur l'ensemble de test:** 0.07102997368792968"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Imputation par SimpleImputer(Mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample a fraction of the data to reduce memory usage\n",
    "data_sample = app_train.sample(frac=0.1, random_state=42)\n",
    "\n",
    "# Convert data types to save memory\n",
    "for col in data_sample.columns:\n",
    "    if data_sample[col].dtype == np.float64:\n",
    "        data_sample[col] = data_sample[col].astype(np.float32)\n",
    "    if data_sample[col].dtype == np.int64:\n",
    "        data_sample[col] = data_sample[col].astype(np.int32)\n",
    "\n",
    "X = data_sample.drop('TARGET', axis=1)\n",
    "y = data_sample['TARGET']\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "# Assuming 'app_train' is your initial DataFrame\n",
    "# Continuing with the already defined data_sample for the example\n",
    "\n",
    "# Creating a baseline pipeline\n",
    "baseline_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Imputation using the mean\n",
    "    ('model', LinearRegression())  # Linear Regression model\n",
    "])\n",
    "\n",
    "# Defining the scoring metric as negative MSE\n",
    "mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)\n",
    "\n",
    "# Executing cross-validation and converting MSE scores to positive\n",
    "cv_scores = cross_val_score(baseline_pipeline, X, y, cv=5, scoring=mse_scorer)\n",
    "cv_scores_positive = -cv_scores\n",
    "\n",
    "# Calculating the mean of the positive MSE scores\n",
    "mean_cv_score = np.mean(cv_scores_positive)\n",
    "\n",
    "# Printing the results\n",
    "print(\"MSE for each cross-validation :\", cv_scores_positive)\n",
    "print(\"Mean MSE scores across cross-validations :\", mean_cv_score)\n",
    "\n",
    "# Creating a DataFrame to store the results\n",
    "results_df = pd.DataFrame(cv_scores_positive, columns=['MSE'])\n",
    "results_df.loc['Mean'] = mean_cv_score\n",
    "\n",
    "# Saving the results to a CSV file\n",
    "results_df.to_csv('cv_mse_results.csv', index_label='Validation Fold')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultats** <br>\n",
    "Validation Fold : 0 <br>\n",
    "MSE: 0.07248985128343831 <br>\n",
    "Validation Fold : 1 <br>\n",
    "MSE: 0.06996261719078271 <br>\n",
    "Validation Fold :2 <br>\n",
    "MSE: 0.07037241326004501 <br>\n",
    "Validation Fold : 3 <br>\n",
    "MSE: 0.0701993874565854 <br>\n",
    "Validation Fold :4 <br>\n",
    "MSE: 0.07247808597927778 <br>\n",
    "Moyenne MSE,0.07110047103402585 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Imputation par SimpleImputer(Median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Résultats** <br>\n",
    "\n",
    "Validation Fold :0<br>\n",
    "MSE:0.07241020685855701<br>\n",
    "Validation Fold :1<br>\n",
    "MSE:0.06994843129380458<br>\n",
    "Validation Fold :2<br>\n",
    "MSE:0.07038380135291558<br>\n",
    "Validation Fold :3<br>\n",
    "MSE:0.07017891302627659<br>\n",
    "Validation Fold :4<br>\n",
    "MSE:0.07249469414473592<br>\n",
    "Moyenne:0.07108320933525794<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Interprétation des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme on peut le voir les résultats obtenu sont assez similaire on va choisir une imputation par la médiane car il obtient un meilleur résultats que par la moyenne et demande moins de temps d'éxécution que le KNN imputer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imputation par la médianne "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "scoring_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
